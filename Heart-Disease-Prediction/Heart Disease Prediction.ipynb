{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjYCT4FfKs-W"
   },
   "source": [
    "# <center> Heart Disease Prediction Classifier\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5E_uzc5Ks-e"
   },
   "source": [
    "### Import libraries\n",
    "\n",
    "Let's first import all the necessary libraries. I'll use `numpy` and `pandas` to start with. For visualization, I will use `pyplot` subpackage of `matplotlib`, use `rcParams` to add styling to the plots and `rainbow` for colors. For implementing Machine Learning models and processing of data, I will use the `sklearn` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributes\n",
    "1)sex: male(0) or female(1);(Nominal)\n",
    "2)age: age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
    "3)cp:Clinical prediction models (CPMs) estimate the probability of clinical outcomes and hold the potential to improve decision making and individualize care. For patients with cardiovascular disease\n",
    "4)trestbps:resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern\n",
    "5)chol {serum cholestoral in mg/dl} : above 200 is cause for concern.\n",
    "6)fbs: The person's fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "7)restecg {resting electrocardiographic results} : People with value 1 (signals non-normal heart beat, can range from mild symptoms to severe problems) are more likely to have heart disease. exang {exercise induced angina} : People with value 0 (No ==> exercice induced angina) have heart disease more than people with value 1 (Yes ==> exercice induced angina)\n",
    "8)thalach {maximum heart rate achieved} : People how acheived a maximum more than 140 are more likely to have heart disease.\n",
    "9)exang {exercise-induced angina}: people with a value of 0 (No ==> angina induced by exercise) have more heart disease than people with a value of 1 (Yes ==> angina induced by exercise)\n",
    "10)Old peak:t ype of chest pain and maximum heart rate achieved are also important for predicting heart disease\n",
    "11)slope: The slope of the peak exercise ST segment is the most important subject to predict heart disease\n",
    "12)ca {number of major vessels (0-3) stained by fluoroscopy}: the more blood movement the better, so people with ca equal to 0 are more likely to have heart disease\n",
    "13)thal {thalium stress result}: People with a thal value of 2 (defect corrected: once was a defect but ok now) are more likely to have heart disease.\n",
    "14)target: The goal of our heart disease prediction project is to determine if a patient should be diagnosed with heart disease or not, which is a binary outcome, so: Positive result = 1, the patient will be diagnosed with heart disease. Negative result = 0, the patient will not be diagnosed with heart disease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1659454044925,
     "user": {
      "displayName": "4C3 LOKESH",
      "userId": "13664538715620297907"
     },
     "user_tz": -330
    },
    "id": "FoKgW6rrKs-g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.cm import rainbow\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeNreMESKs-i"
   },
   "source": [
    "For processing the data, I'll import a few libraries. To split the available dataset for testing and training, I'll use the `train_test_split` method. To scale the features, I am using `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1659454050466,
     "user": {
      "displayName": "4C3 LOKESH",
      "userId": "13664538715620297907"
     },
     "user_tz": -330
    },
    "id": "OyWsBx-sKs-i"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRbplaukKs-j"
   },
   "source": [
    "Next, I'll import all the Machine Learning algorithms I will be using.\n",
    "1. K Neighbors Classifier\n",
    "2. Support Vector Classifier\n",
    "3. Decision Tree Classifier\n",
    "4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1659454059121,
     "user": {
      "displayName": "4C3 LOKESH",
      "userId": "13664538715620297907"
     },
     "user_tz": -330
    },
    "id": "3EN1YhPsKs-k"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJBgnvl0Ks-l"
   },
   "source": [
    "### Import dataset\n",
    "\n",
    "Now that we have all the libraries we will need, I can import the dataset and take a look at it. The dataset is stored in the file `dataset.csv`. I'll use the pandas `read_csv` method to read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "error",
     "timestamp": 1659454070624,
     "user": {
      "displayName": "4C3 LOKESH",
      "userId": "13664538715620297907"
     },
     "user_tz": -330
    },
    "id": "i1X9833CKs-m",
    "outputId": "9d34f581-1afc-41a7-86fa-4b59632fe2bd"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvNwbcRQKs-n"
   },
   "source": [
    "The dataset is now loaded into the variable `dataset`. I'll just take a glimpse of the data using the `desribe()` and `info()` methods before I actually start processing and visualizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HiWkfMP5Ks-n",
    "outputId": "6ac30e4a-1250-4937-9566-7e1d29c00487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sgzmi5MwKs-p"
   },
   "source": [
    "Looks like the dataset has a total of 303 rows and there are no missing values. There are a total of `13 features` along with one target value which we wish to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "error",
     "timestamp": 1659454080349,
     "user": {
      "displayName": "4C3 LOKESH",
      "userId": "13664538715620297907"
     },
     "user_tz": -330
    },
    "id": "vU232awPKs-p",
    "outputId": "66987552-2801-4715-d1f4-ba5fd4f77b7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8Gd3jc0Ks-q"
   },
   "source": [
    "The scale of each feature column is different and quite varied as well. While the maximum for `age` reaches 77, the maximum of `chol` (serum cholestoral) is 564."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "horhEKMrKs-q"
   },
   "source": [
    "### Understanding the data\n",
    "\n",
    "Now, we can use visualizations to better understand our data and then look at any processing we might want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3OZSKP4bKs-r",
    "outputId": "9b8fcef5-664c-4600-fcec-d027b605fcf7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6080783e47a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 20, 14\n",
    "plt.matshow(dataset.corr())\n",
    "plt.yticks(np.arange(dataset.shape[1]), dataset.columns)\n",
    "plt.xticks(np.arange(dataset.shape[1]), dataset.columns)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLUJsa--Ks-r"
   },
   "source": [
    "Taking a look at the correlation matrix above, it's easy to see that a few features have negative correlation with the target value while some have positive.\n",
    "Next, I'll take a look at the histograms for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_CaO7BOKs-s",
    "outputId": "8019d431-d86f-4dfa-82e6-030c708c2888"
   },
   "outputs": [],
   "source": [
    "dataset.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG4NlnFcKs-s"
   },
   "source": [
    "Taking a look at the histograms above, I can see that each feature has a different range of distribution. Thus, using scaling before our predictions should be of great use. Also, the categorical features do stand out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5UZGLS1Ks-t"
   },
   "source": [
    "It's always a good practice to work with a dataset where the target classes are of approximately equal size. Thus, let's check for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZJrZIxfKs-u",
    "outputId": "2a7f214b-8cc1-4c17-bdbc-38cc60c25ff4"
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8,6\n",
    "plt.bar(dataset['target'].unique(), dataset['target'].value_counts(), color = ['red', 'green'])\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Target Classes')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of each Target Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-BrcI6zKs-v"
   },
   "source": [
    "The two classes are not exactly 50% each but the ratio is good enough to continue without dropping/increasing our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njZRfGIVKs-w"
   },
   "source": [
    "### Data Processing\n",
    "\n",
    "After exploring the dataset, I observed that I need to convert some categorical variables into dummy variables and scale all the values before training the Machine Learning models.\n",
    "First, I'll use the `get_dummies` method to create dummy columns for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxvaK2hHKs-w"
   },
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMJKpe-DKs-w"
   },
   "source": [
    "Now, I will use the `StandardScaler` from `sklearn` to scale my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HKiprmsKs-x"
   },
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler()\n",
    "columns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "dataset[columns_to_scale] = standardScaler.fit_transform(dataset[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwjt6ZmDKs-x"
   },
   "source": [
    "The data is not ready for our Machine Learning application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqjCC8BcKs-x"
   },
   "source": [
    "### Machine Learning\n",
    "\n",
    "I'll now import `train_test_split` to split our dataset into training and testing datasets. Then, I'll import all Machine Learning models I'll be using to train and test the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UShXFBmCKs-x"
   },
   "outputs": [],
   "source": [
    "y = dataset['target']\n",
    "X = dataset.drop(['target'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlDIr2-GKs-y"
   },
   "source": [
    "#### K Neighbors Classifier\n",
    "\n",
    "The classification score varies based on different values of neighbors that we choose. Thus, I'll plot a score graph for different values of K (neighbors) and check when do I achieve the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0LPInbgKs-y"
   },
   "outputs": [],
   "source": [
    "knn_scores = []\n",
    "for k in range(1,21):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    knn_scores.append(knn_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHVW-HvzKs-y"
   },
   "source": [
    "I have the scores for different neighbor values in the array `knn_scores`. I'll now plot it and see for which value of K did I get the best scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v16D9r2HKs-y",
    "outputId": "be75d575-b7e9-4cbf-99a4-592488f87e83"
   },
   "outputs": [],
   "source": [
    "plt.plot([k for k in range(1, 21)], knn_scores, color = 'red')\n",
    "for i in range(1,21):\n",
    "    plt.text(i, knn_scores[i-1], (i, knn_scores[i-1]))\n",
    "plt.xticks([i for i in range(1, 21)])\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('K Neighbors Classifier scores for different K values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQm1vEP7Ks-z"
   },
   "source": [
    "From the plot above, it is clear that the maximum score achieved was `0.87` for the 8 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRUCmus3Ks-z",
    "outputId": "22248833-7f30-4cb7-ba83-cd1874ab8776"
   },
   "outputs": [],
   "source": [
    "print(\"The score for K Neighbors Classifier is {}% with {} nieghbors.\".format(knn_scores[7]*100, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh4ITAijKs-z"
   },
   "source": [
    "#### Support Vector Classifier\n",
    "\n",
    "There are several kernels for Support Vector Classifier. I'll test some of them and check which has the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AGI_r8XKs-0"
   },
   "outputs": [],
   "source": [
    "svc_scores = []\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in range(len(kernels)):\n",
    "    svc_classifier = SVC(kernel = kernels[i])\n",
    "    svc_classifier.fit(X_train, y_train)\n",
    "    svc_scores.append(svc_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgAE6rDIKs-0"
   },
   "source": [
    "I'll now plot a bar plot of scores for each kernel and see which performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upKjzkgZKs-0",
    "outputId": "0935693c-aed6-4d08-e14a-4948d14702ce"
   },
   "outputs": [],
   "source": [
    "colors = rainbow(np.linspace(0, 1, len(kernels)))\n",
    "plt.bar(kernels, svc_scores, color = colors)\n",
    "for i in range(len(kernels)):\n",
    "    plt.text(i, svc_scores[i], svc_scores[i])\n",
    "plt.xlabel('Kernels')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Support Vector Classifier scores for different kernels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFFk-CtkKs-1"
   },
   "source": [
    "The `linear` kernel performed the best, being slightly better than `rbf` kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNh5eNr6Ks-1",
    "outputId": "5fe3fc04-f21c-4ae9-82c9-336a28618f58"
   },
   "outputs": [],
   "source": [
    "print(\"The score for Support Vector Classifier is {}% with {} kernel.\".format(svc_scores[0]*100, 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTzB2pkEKs-1"
   },
   "source": [
    "#### Decision Tree Classifier\n",
    "\n",
    "Here, I'll use the Decision Tree Classifier to model the problem at hand. I'll vary between a set of `max_features` and see which returns the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1P9bXezKs-1"
   },
   "outputs": [],
   "source": [
    "dt_scores = []\n",
    "for i in range(1, len(X.columns) + 1):\n",
    "    dt_classifier = DecisionTreeClassifier(max_features = i, random_state = 0)\n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "    dt_scores.append(dt_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0jtguF2Ks-2"
   },
   "source": [
    "I selected the maximum number of features from 1 to 30 for split. Now, let's see the scores for each of those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5rfQC-NKs-2",
    "outputId": "25676fb9-2c2e-47c0-ec17-58b9d93b77bd"
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1, len(X.columns) + 1)], dt_scores, color = 'green')\n",
    "for i in range(1, len(X.columns) + 1):\n",
    "    plt.text(i, dt_scores[i-1], (i, dt_scores[i-1]))\n",
    "plt.xticks([i for i in range(1, len(X.columns) + 1)])\n",
    "plt.xlabel('Max features')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Decision Tree Classifier scores for different number of maximum features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLcXDCJvKs-2"
   },
   "source": [
    "The model achieved the best accuracy at three values of maximum features, `2`, `4` and `18`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJXJitcFKs-2",
    "outputId": "4d382f7f-5a86-40c8-9066-2015e0f57a70"
   },
   "outputs": [],
   "source": [
    "print(\"The score for Decision Tree Classifier is {}% with {} maximum features.\".format(dt_scores[17]*100, [2,4,18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFLKS2i5Ks-3"
   },
   "source": [
    "#### Random Forest Classifier\n",
    "\n",
    "Now, I'll use the ensemble method, Random Forest Classifier, to create the model and vary the number of estimators to see their effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0FN8pisKs-3"
   },
   "outputs": [],
   "source": [
    "rf_scores = []\n",
    "estimators = [10, 100, 200, 500, 1000]\n",
    "for i in estimators:\n",
    "    rf_classifier = RandomForestClassifier(n_estimators = i, random_state = 0)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    rf_scores.append(rf_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6rKH6lTKs-3"
   },
   "source": [
    "The model is trained and the scores are recorded. Let's plot a bar plot to compare the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwI5uFChKs-3",
    "outputId": "be0747cf-5894-4a7e-fa58-f5afa365692a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = rainbow(np.linspace(0, 1, len(estimators)))\n",
    "plt.bar([i for i in range(len(estimators))], rf_scores, color = colors, width = 0.8)\n",
    "for i in range(len(estimators)):\n",
    "    plt.text(i, rf_scores[i], rf_scores[i])\n",
    "plt.xticks(ticks = [i for i in range(len(estimators))], labels = [str(estimator) for estimator in estimators])\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Random Forest Classifier scores for different number of estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWNIMQ4OKs-4"
   },
   "source": [
    "The maximum score is achieved when the total estimators are 100 or 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2JJ3g7zKs-4",
    "outputId": "cb2f81e7-bf00-4c55-face-8a34b21773d6"
   },
   "outputs": [],
   "source": [
    "print(\"The score for Random Forest Classifier is {}% with {} estimators.\".format(rf_scores[1]*100, [100, 500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIe0cC0IKs-4"
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "In this project, I used Machine Learning to predict whether a person is suffering from a heart disease. After importing the data, I analysed it using plots. Then, I did generated dummy variables for categorical features and scaled other features. \n",
    "I then applied four Machine Learning algorithms, `K Neighbors Classifier`, `Support Vector Classifier`, `Decision Tree Classifier` and `Random Forest Classifier`. I varied parameters across each model to improve their scores.\n",
    "In the end, `K Neighbors Classifier` achieved the highest score of `87%` with `8 nearest neighbors`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Heart Disease Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
